{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1ztLFNnKJs5MLN98zc2sE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reachforaryan/image_captioning/blob/main/img_cptn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww90XE4zAf9S"
      },
      "outputs": [],
      "source": [
        "from os import listdir                        #retrun list of name of file \n",
        "from pickle import dump                       #used to searealise and deserealise\n",
        "from keras.application.vgg16 import VGG16     \n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.imafe import img_to_array\n",
        "from keras.application.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "def extract_feature(directory):\n",
        "  #loading the model\n",
        "  model=VGG16()\n",
        "  #restructure the model\n",
        "  model.layer.pop()\n",
        "  model=Model(inputes=model.inputs,outputs=model.layers[-1].output)\n",
        "  #summarize\n",
        "  print(model.summary())\n",
        "  #extract feature from each photo\n",
        "  features = dict()\n",
        "  for name in listdir(directory):\n",
        "    #load an image from file\n",
        "    filename=directory + '/' + name\n",
        "    image=load_img(filename,target_size=(224,224))\n",
        "    #convert the image pixels to a numpy array\n",
        "    image=imt_to_array(image)\n",
        "    #reshape data for the model\n",
        "    image = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n",
        "    #prepare the image for the VGG model\n",
        "    image=preprocess_input(image)\n",
        "    #get feature\n",
        "    feature = model.predict(image,verbase=0)\n",
        "    #get iamge id\n",
        "    image_id = name.split('.')[0]\n",
        "    #store feature\n",
        "    features[image_id]=feature\n",
        "    print('>%s'%name)\n",
        "  return features\n",
        "\n",
        "#extract features from all images\n",
        "directory = 'Flicker8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Exctracted Feature: %d'%len(features))\n",
        "#save to file\n",
        "dump(features,open('Image_Caption_Project_Model_Data/features.pkl','wb'))\n",
        "\n",
        "\n"
      ]
    }
  ]
}